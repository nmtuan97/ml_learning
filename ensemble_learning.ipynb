{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"E:/nmtuan97/1_scripts/ml_learning/data_test.csv\", delimiter=',')\n",
    "X = data[:,:1]\n",
    "y = data[:,1:2]\n",
    "\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25)\n",
    "\n",
    "X_test = np.sort(X_test, axis=0)\n",
    "y_test = np.sort(y_test, axis=0)\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "plt.plot(X, y, 'o', label='data looks like')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting Regressor: Training set will be trained using different training algorithms (eg. SVM, DecisionTree,...), and then the total prediction will be made from different model to get the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Regressor:\n",
    "svr_ = SVR(kernel = 'rbf', C=100000, gamma=500)\n",
    "dtree_ = DecisionTreeRegressor(max_depth=5)\n",
    "rf_rg_ = RandomForestRegressor()\n",
    "\n",
    "voting_rg = VotingRegressor(estimators=[('svr', svr_), ('dtree', dtree_), ('rf', rf_rg_)])\n",
    "voting_rg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "for rg in (svr_, dtree_, rf_rg_, voting_rg):\n",
    "    rg.fit(X_train,y_train)\n",
    "    y_pred = rg.predict(X_test)\n",
    "    print(rg.__class__.__name__, r2_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to get a diverse set of classifiers is to use very different training algorithms, as just discussed. Another approach is to use the same training algorithm for every predictor, but to train them on different random subsets of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "bag_rg_ = BaggingRegressor(DecisionTreeRegressor(max_depth=5), n_estimators=5000, max_samples=180, bootstrap=True, n_jobs=None, oob_score=True)\n",
    "bag_rg_.fit(X_train,y_train)\n",
    "y_pred = bag_rg_.predict(X_test)\n",
    "print(r2_score(y_test,y_pred))\n",
    "bag_rg_.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_rg_ = RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, n_jobs=None)\n",
    "rf_rg_.fit(X_train,y_train)\n",
    "y_pred = rf_rg_.predict(X_test)\n",
    "print(r2_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
